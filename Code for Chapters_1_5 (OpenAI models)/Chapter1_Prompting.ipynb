{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chapter 1\n",
    "\n",
    "    - This notebook contains the code for Chapter 1 of the book"
   ],
   "id": "66bf70e66c2344c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipe 1.2.1: Load and chat with the OpenAI models",
   "id": "ccf5a63e1141c092"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T03:21:47.616180Z",
     "start_time": "2025-07-09T03:21:40.384758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from getpass import getpass \n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = getpass() \n"
   ],
   "id": "ff3937e62f346368",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T03:28:55.961130Z",
     "start_time": "2025-07-09T03:28:44.828639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## Step 1: Inherit the key supplied in the previous step\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "## Step 2: Define a model\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model = \"gpt-4o-mini\")\n",
    "\n",
    "## Step 3: Specify the prompt\n",
    "prompt_input = \"\"\"\n",
    "Write a message to welcome users to interact with an LLM-powered chatbot that answers question related to a school\"\"\"\n",
    "\n",
    "## Step 4: Call the invoke method\n",
    "response = llm.invoke(prompt_input)\n",
    "\n",
    "\n",
    "print(response.content) \n",
    " \n"
   ],
   "id": "c27224747464031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Welcome to Our School's LLM-Powered Chatbot!\n",
      "\n",
      "Dear Students, Parents, and Staff,\n",
      "\n",
      "We are excited to introduce our new LLM-powered chatbot, designed to assist you with all your school-related questions! Whether you need information about class schedules, extracurricular activities, school policies, or any other inquiries, our chatbot is here to help.\n",
      "\n",
      "Feel free to ask about:\n",
      "- Academic subjects and resources\n",
      "- Upcoming events and deadlines\n",
      "- School facilities and services\n",
      "- Ways to connect with teachers and staff\n",
      "\n",
      "Our chatbot is available 24/7, making it easy for you to get the information you need at your convenience! Simply type your question in the chat window, and our intelligent assistant will provide you with accurate and helpful responses.\n",
      "\n",
      "We hope this tool enhances your experience at our school, and we encourage you to interact and explore what our chatbot can do for you. Your feedback is valuable, so please let us know how we can improve this service!\n",
      "\n",
      "Happy chatting!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your School's Name] Team\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipe 1.3.1a: Defining a Prompt withâ€¯PromptTemplate.from_template() ",
   "id": "9e27f61acad2bf0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "68434871aa279f45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:14:30.948923Z",
     "start_time": "2025-07-10T12:14:30.927851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    " \n",
    "## Define the template string with a variable\n",
    "template_string = \"Translate this technical concept into everyday language for our customers: {concept}\"\n",
    " \n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template = template_string\n",
    ")\n",
    " \n",
    "## Actual prompt\n",
    "prompt = prompt_template.invoke({\"concept\":\"Curriculum development\"})\n",
    " \n",
    "print(prompt)\n",
    "\n",
    "print(prompt.text)\n"
   ],
   "id": "79b6d35fbc6e7526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Translate this technical concept into everyday language for our customers: Curriculum development'\n",
      "Translate this technical concept into everyday language for our customers: Curriculum development\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipe 1.3.1b: Defining a prompt template as a constructor ( HF model)",
   "id": "9a975ed1229bb182"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T21:44:17.361841Z",
     "start_time": "2025-07-10T21:44:17.348544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    " \n",
    "# Step 1: Define a list of user roles (could come from a UI selection or session data)\n",
    "user_roles = [\"parent\", \"student\", \"teacher\", \"guest\"]\n",
    "\n",
    "# Step 2: Define a list to keep variants of the prompt\n",
    "template_strings = []\n",
    "\n",
    "# Step 3: Define a function to build a customized prompt string for each user role\n",
    "for user_role in user_roles:\n",
    "    if user_role == \"parent\":\n",
    "        role_line = \"You are answering a question from a parent.\"\n",
    "    elif user_role == \"student\":\n",
    "        role_line = \"You are assisting a student.\"\n",
    "    else:\n",
    "        # Fallback for teacher, guest, or other roles\n",
    "        role_line = \"I'm Eli, your helpful administrative assistant.\"\n",
    " \n",
    "    # Construct the full prompt string with a {question} placeholder\n",
    "    template = f\"\"\"{role_line} Answer the following question clearly and concisely: {{question}}\"\"\"\n",
    "    template_strings.append(template)\n",
    " \n",
    "## Step 4: Convert each template string into a PromptTemplate instance\n",
    "prompts = [\n",
    "    PromptTemplate(template=template_string, input_variables=[\"question\"])\n",
    "    for template_string in template_strings]\n",
    "\n",
    "# Step 5: Demonstrate how each prompt responds to the same input question\n",
    "print(prompts[0].invoke({\"question\": \"What is the school's policy around uniforms?\"}))\n",
    "print(prompts[1].invoke({\"question\": \"What is the school's policy around uniforms?\"}))\n",
    "print(prompts[2].invoke({\"question\": \"What is the school's policy around uniforms?\"}))\n"
   ],
   "id": "33f5332973973a92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=\"You are answering a question from a parent. Answer the following question clearly and concisely: What is the school's policy around uniforms?\"\n",
      "text=\"You are assisting a student. Answer the following question clearly and concisely: What is the school's policy around uniforms?\"\n",
      "text=\"I'm Eli, your helpful administrative assistant. Answer the following question clearly and concisely: What is the school's policy around uniforms?\"\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipe 1.3.1c: Integrating the prompt template with an OpenAI model",
   "id": "761e9154cc9daed8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "## Step 1: Define a template string\n",
    "template_string = \"Translate this technical concept into everyday language for our customers: {concept}\"\n",
    " \n",
    "## Step 2: Define the actual prompt template\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template = template_string\n",
    ")\n",
    "\n",
    "## Step 3: Define the LLM \n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, \n",
    "                 model = \"gpt-4o-mini\")\n",
    " \n",
    "## Step 4: Format the prompt\n",
    "formatted_prompt = prompt_template.format(concept=\"Curriculum development\")\n",
    "\n",
    "\n",
    "## Invoke the llm with the formatted_prompt\n",
    "response = llm.invoke(formatted_prompt)\n",
    " \n",
    " \n",
    "## Print the response\n",
    "print(response.content)\n"
   ],
   "id": "ea036c660863f7f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipe 1.3.2a: Integrating the prompt template with an OpenAI model via the LCEL",
   "id": "eb5b784ab89eb0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:31:17.580862Z",
     "start_time": "2025-07-11T11:31:07.743479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from getpass import getpass \n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = getpass() \n"
   ],
   "id": "e4970bdb7318fb8a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:31:42.563335Z",
     "start_time": "2025-07-11T11:31:42.554971Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY",
   "id": "fe27b0e998b115ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:31:50.257143Z",
     "start_time": "2025-07-11T11:31:46.996994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## Step 1: Define the template string\n",
    "template = \"Translate this technical concept into everyday language for our customers: {concept}\"\n",
    " \n",
    "## Step 2: Define the template body\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template = template\n",
    ")\n",
    "\n",
    "## Step 3: Define the LLM \n",
    "llm = ChatOpenAI(api_key = OPENAI_API_KEY, model = \"gpt-4o-mini\")\n",
    " \n",
    "## Step 4: Create the chain\n",
    "llm_chain = prompt_template | llm\n",
    "\n",
    "## Step 5: Call the invoke method on the chain\n",
    "response = llm_chain.invoke({\"concept\":\"Curriculum development\"})\n",
    "\n",
    "\n",
    "## Print the response \n",
    "print(response.content)\n"
   ],
   "id": "a92bea8498f648f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curriculum development is the process of creating a structured plan for what students will learn in a course or program. Think of it as designing a roadmap for education. It involves deciding the subjects, topics, and skills that need to be taught, choosing the best methods for teaching them, and figuring out how to assess students' understanding. The goal is to ensure that students gain the knowledge and skills they need in a way that's engaging and effective. In simpler terms, itâ€™s all about making learning clear, organized, and relevant for everyone involved!\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
